{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import scipy\n",
    "\n",
    "import sys\n",
    "sys.path.append('/nfs/juhu/data/rakhasan/bystander-detection/code-repos/pose-tensorflow-master/')\n",
    "base_path='/nfs/juhu/data/rakhasan/bystander-detection/code-repos/pose-tensorflow-master/'\n",
    "\n",
    "from config import load_config,cfg_from_file\n",
    "from dataset.factory import create as create_dataset\n",
    "from dataset.pose_dataset import Batch, merge_batch\n",
    "from nnet.predict import *\n",
    "from util import visualize\n",
    "from multiperson.posenms import pose_nms\n",
    "from predict_2stage import write_posetrack_predictions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_name(path):\n",
    "    split = path.split(\".\")\n",
    "    assert(len(split) == 2)\n",
    "    base_path = split[0]\n",
    "    return base_path.replace(\"/\", \"_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "total_num_persons 0\n",
      "INFO:tensorflow:Restoring parameters from data/snapshot-250000\n"
     ]
    }
   ],
   "source": [
    "cfg = cfg_from_file('pose_cfg.yaml')\n",
    "dataset = create_dataset(cfg)\n",
    "dataset.set_shuffle(False)\n",
    "dataset.set_test_mode(True)\n",
    "num_images = len(dataset.data)\n",
    "\n",
    "tf.reset_default_graph() \n",
    "sess, inputs, outputs = setup_pose_prediction(cfg)\n",
    "\n",
    "all_poses = []\n",
    "all_box_conf = []\n",
    "all_boxes = []\n",
    "\n",
    "out_dir = cfg.scoremap_dir\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "item = dataset.data[k]\n",
    "\n",
    "boxes = item.boxes\n",
    "box_conf = item.box_conf\n",
    "valid_boxes = box_conf >= cfg.person_min_conf\n",
    "boxes = boxes[valid_boxes]\n",
    "box_conf = box_conf[valid_boxes]\n",
    "num_boxes = boxes.shape[0]\n",
    "num_batches = int(math.ceil(num_boxes / cfg.batch_size))\n",
    "\n",
    "poses = np.zeros((0, cfg.num_joints, 3), dtype=np.float64)\n",
    "sm_size = np.ceil(cfg.crop_size / (cfg.stride * 2)).astype(int) * 2\n",
    "scoremaps = np.zeros((0, sm_size, sm_size, cfg.num_joints), dtype=np.float32)\n",
    "locref_maps = np.zeros((0, sm_size, sm_size, cfg.num_joints, 2), dtype=np.float32)\n",
    "scales = np.zeros((0), dtype=np.float32)\n",
    "top_lefts = np.zeros((0, 2), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(num_batches):\n",
    "    start = j * cfg.batch_size\n",
    "    end = min(start + cfg.batch_size, num_boxes)\n",
    "    batches = []\n",
    "    for i in range(start, end):\n",
    "        item.person_idx = i\n",
    "        batch = dataset.make_batch(item, cfg.global_scale, mirror=False)\n",
    "        assert(batch is not None)\n",
    "        batches.append(batch)\n",
    "    batch = batches[0] if len(batches) == 1 else merge_batch(batches)\n",
    "\n",
    "    inputs_to_net = batch[Batch.inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_np = sess.run(outputs, feed_dict={inputs: inputs_to_net})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['part_prob', 'locref'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(outputs_np)\n",
    "outputs_np.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cnn_output2(outputs_np, cfg, pairwise_stats = None):\n",
    "    scmap = outputs_np['part_prob']\n",
    "    scmap = np.squeeze(scmap)\n",
    "    locref = None\n",
    "    pairwise_diff = None\n",
    "    if cfg.location_refinement:\n",
    "        locref = np.squeeze(outputs_np['locref'])\n",
    "        shape = locref.shape\n",
    "        locref = np.reshape(locref, (shape[0], shape[1], -1, 2))\n",
    "        locref *= cfg.locref_stdev\n",
    "    if cfg.pairwise_predict:\n",
    "        pairwise_diff = np.squeeze(outputs_np['pairwise_pred'])\n",
    "        shape = pairwise_diff.shape\n",
    "        pairwise_diff = np.reshape(pairwise_diff, (shape[0], shape[1], -1, 2))\n",
    "        num_joints = cfg.num_joints\n",
    "        for pair in pairwise_stats:\n",
    "            pair_id = (num_joints - 1) * pair[0] + pair[1] - int(pair[0] < pair[1])\n",
    "            pairwise_diff[:, :, pair_id, 0] *= pairwise_stats[pair][\"std\"][0]\n",
    "            pairwise_diff[:, :, pair_id, 0] += pairwise_stats[pair][\"mean\"][0]\n",
    "            pairwise_diff[:, :, pair_id, 1] *= pairwise_stats[pair][\"std\"][1]\n",
    "            pairwise_diff[:, :, pair_id, 1] += pairwise_stats[pair][\"mean\"][1]\n",
    "    return scmap, locref, pairwise_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42, 42, 14), (42, 42, 28))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=0\n",
    "output_np = {\n",
    "            \"part_prob\" : outputs_np[\"part_prob\"][idx,:,:,:],\n",
    "            \"locref\": outputs_np[\"locref\"][idx, :, :, :]\n",
    "            }\n",
    "output_np['part_prob'].shape,output_np['locref'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "scmap, locref, _ = extract_cnn_output2(output_np, cfg)\n",
    "pose = argmax_pose_predict(scmap, locref, cfg.stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14, 3), (42, 42, 14))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose.shape,scmap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_net(visualise, cache_scoremaps, development):\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "    cfg = load_config()\n",
    "    dataset = create_dataset(cfg)\n",
    "    dataset.set_shuffle(False)\n",
    "    dataset.set_test_mode(True)\n",
    "\n",
    "    num_images = len(dataset.data)\n",
    "\n",
    "    sess, inputs, outputs = setup_pose_prediction(cfg)\n",
    "\n",
    "    all_poses = []\n",
    "    all_box_conf = []\n",
    "    all_boxes = []\n",
    "\n",
    "    out_dir = cfg.scoremap_dir\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    for k in range(num_images):\n",
    "        print('processing image {}/{}'.format(k, num_images-1))\n",
    "\n",
    "        item = dataset.data[k]\n",
    "\n",
    "        boxes = item.boxes\n",
    "        box_conf = item.box_conf\n",
    "        valid_boxes = box_conf >= cfg.person_min_conf\n",
    "        boxes = boxes[valid_boxes]\n",
    "        box_conf = box_conf[valid_boxes]\n",
    "        num_boxes = boxes.shape[0]\n",
    "        num_batches = int(math.ceil(num_boxes / cfg.batch_size))\n",
    "\n",
    "        poses = np.zeros((0, cfg.num_joints, 3), dtype=np.float64)\n",
    "\n",
    "        sm_size = np.ceil(cfg.crop_size / (cfg.stride * 2)).astype(int) * 2\n",
    "        scoremaps = np.zeros((0, sm_size, sm_size, cfg.num_joints), dtype=np.float32)\n",
    "        locref_maps = np.zeros((0, sm_size, sm_size, cfg.num_joints, 2), dtype=np.float32)\n",
    "        scales = np.zeros((0), dtype=np.float32)\n",
    "        top_lefts = np.zeros((0, 2), dtype=np.float32)\n",
    "\n",
    "        for j in range(num_batches):\n",
    "            start = j * cfg.batch_size\n",
    "            end = min(start + cfg.batch_size, num_boxes)\n",
    "            batches = []\n",
    "            for i in range(start, end):\n",
    "                item.person_idx = i\n",
    "                batch = dataset.make_batch(item, cfg.global_scale, mirror=False)\n",
    "                assert(batch is not None)\n",
    "                batches.append(batch)\n",
    "            batch = batches[0] if len(batches) == 1 else merge_batch(batches)\n",
    "\n",
    "            inputs_to_net = batch[Batch.inputs]\n",
    "            \"\"\"\n",
    "            print(inputs_to_net.shape)\n",
    "            num_in_batch = inputs_to_net.shape\n",
    "            if num_in_batch < cfg.batch_size:\n",
    "                inputs_to_net[cfg.batch_size-1,0,0,0] = 0\n",
    "            \"\"\"\n",
    "            outputs_np = sess.run(outputs, feed_dict={inputs: inputs_to_net})\n",
    "\n",
    "            for idx, i in enumerate(range(start, end)):\n",
    "                item.person_idx = i\n",
    "\n",
    "                output_np = {\n",
    "                    \"part_prob\" : outputs_np[\"part_prob\"][idx,:,:,:],\n",
    "                    \"locref\": outputs_np[\"locref\"][idx, :, :, :]\n",
    "                }\n",
    "                #output_np = {k: v[idx,:,:,:] for (k, v) in outputs_np}\n",
    "\n",
    "                scmap, locref, _ = extract_cnn_output(output_np, cfg)\n",
    "                pose = argmax_pose_predict(scmap, locref, cfg.stride)\n",
    "\n",
    "                #img = np.squeeze(batch[Batch.inputs][idx, :, :, :]).astype('uint8')\n",
    "                #visualize.show_heatmaps(cfg, img, scmap, pose)\n",
    "                #visualize.waitforbuttonpress()\n",
    "\n",
    "                scale = batch[Batch.scale][idx]\n",
    "                top_left = batch[Batch.crop_topleft][idx]\n",
    "                pose[:,[0,1]] /= scale\n",
    "                pose[:,[0,1]] += top_left\n",
    "\n",
    "                pose = np.expand_dims(pose, axis=0)\n",
    "                poses = np.concatenate((poses, pose), axis=0)\n",
    "\n",
    "                scoremaps = np.concatenate((scoremaps, np.expand_dims(scmap, axis=0)), axis=0)\n",
    "                locref_maps = np.concatenate((locref_maps, np.expand_dims(locref, axis=0)), axis=0)\n",
    "                scales = np.concatenate((scales, np.array([scale])), axis=0)\n",
    "                top_lefts = np.concatenate((top_lefts, np.expand_dims(top_left, axis=0)), axis=0)\n",
    "\n",
    "        #base_name = os.path.splitext(os.path.basename(item.im_file))[0]\n",
    "        base_name = get_base_name(item.im_file)\n",
    "        if cache_scoremaps:\n",
    "            cache_name = \"{}.mat\".format(base_name)\n",
    "\n",
    "            out_fn = os.path.join(out_dir, cache_name)\n",
    "            dict = {'scoremaps': scoremaps.astype('float32'),\n",
    "                    'locreg_pred': locref_maps.astype('float32'),\n",
    "                    'scale': scales, 'top_left': top_lefts}\n",
    "            scipy.io.savemat(out_fn, mdict=dict)\n",
    "\n",
    "        if cfg.pose_nms:\n",
    "            poses, box_conf, boxes = pose_nms(poses, box_conf, boxes, cfg)\n",
    "\n",
    "        poses_out_fn = os.path.join(out_dir, \"{}_poses.mat\".format(base_name))\n",
    "        scipy.io.savemat(poses_out_fn, mdict={\"poses\": poses})\n",
    "\n",
    "        all_poses.append(poses)\n",
    "        all_box_conf.append(box_conf)\n",
    "        all_boxes.append(boxes)\n",
    "\n",
    "    np.savez(\"predictions.npz\", all_poses, all_box_conf, all_boxes)\n",
    "    if \"dataset_sequences\" in cfg and cfg.dataset_sequences:\n",
    "        write_posetrack_predictions(cfg, all_poses, all_box_conf, all_boxes)\n",
    "\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "+"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
