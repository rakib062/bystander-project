{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/l/anaconda3-5.2.0/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "#from tqdm import tqdm\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import scipy.misc\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import keras\n",
    "from keras.layers.core import Dense, Flatten, Dropout\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Input\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg19 import VGG19\n",
    "# import the necessary packages\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "\n",
    "# The below is necessary in Python 3.2.3 onwards to\n",
    "# have reproducible behavior for certain hash-based operations.\n",
    "# See these references for further details:\n",
    "# https://docs.python.org/3.4/using/cmdline.html#envvar-PYTHONHASHSEED\n",
    "# https://github.com/keras-team/keras/issues/2280#issuecomment-306959926\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "\n",
    "rn.seed(12345)\n",
    "\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of\n",
    "# non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess) # reference: https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (256, 256)\n",
    "IN_SHAPE = (*IMG_SIZE, 3)\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading features.\n"
     ]
    }
   ],
   "source": [
    "openImg_path = '/nfs/juhu/data/rakhasan/bystander-detection/google-img-db/'\n",
    "survey_path='/nfs/juhu/data/rakhasan/bystander-detection/pilot-study2/'\n",
    "survey_photo_path = survey_path+'/photos/'\n",
    "\n",
    "model_output_path = '/nfs/juhu/data/rakhasan/bystander-detection/code-repos/notebooks/model-output/'\n",
    "\n",
    "print('loading features.')\n",
    "feature_df = pickle.load(open(os.path.join(survey_path, 'features-df.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df_resnet = pickle.load(open(os.path.join(survey_path, 'features-df-resnet.pkl'), 'rb'))\n",
    "#feature_df = feature_df.loc[feature_df_resnet.index]\n",
    "# feature_df['resnet_feature'] = feature_df_resnet.resnet_feature\n",
    "# feature_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['was_aware_num',\n",
       " 'posing_num',\n",
       " 'comfort_num',\n",
       " 'will_num',\n",
       " 'photographer_intention_num',\n",
       " 'replacable_num',\n",
       " 'photo_place_num',\n",
       " 'subject_bystander_num',\n",
       " 'label',\n",
       " 'cropped_photo',\n",
       " 'resized_cropped_img',\n",
       " 'person_distance',\n",
       " 'person_size',\n",
       " 'num_people',\n",
       " 'Human_eye',\n",
       " 'Human_beard',\n",
       " 'Human_mouth',\n",
       " 'Human_body',\n",
       " 'Human_foot',\n",
       " 'Human_leg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(feature_df_resnet.columns)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "dic = dict()\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    for index, row in feature_df_resnet.iterrows():\n",
    "        tensor = tf.convert_to_tensor(\n",
    "            row.resnet_feature,\n",
    "            dtype=None,\n",
    "            name=None,\n",
    "            preferred_dtype=None\n",
    "        )\n",
    "\n",
    "        p=GlobalAveragePooling2D()(tensor)\n",
    "        dic[index] = p.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.7821752e-01, 1.9637873e+00, 1.2800893e-01, ..., 9.8553133e-01,\n",
       "       1.8732380e-03, 1.9474829e-02], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic['1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(dic, open(survey_path+'resnet_features_averaged.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "visual_features = pd.DataFrame()\n",
    "for i in tqdm(range(131072)):\n",
    "    visual_features['resnet_feat_{}'.format(i)] = feature_df_resnet.apply(lambda row: row.res_flat[i], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df_resnet['res_flat']=feature_df_resnet.apply(lambda row: row.resnet_feature.flatten(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Add resnet feature in the feature dataframe'''\n",
    "#feature_df['resnet_feature'] = resnet_model.predict(\n",
    "    #np.array(list(feature_df.resized_cropped_img),batch_size=BATCH_SIZE), axis=1)\n",
    "#feature_df['resnet_feature'] = feature_df.apply(lambda row: row.resnet_feature.flatten(), axis=1)\n",
    "feature_df['resnet_feature_zscore'] = feature_df.apply(lambda row: row.resnet_feature.apply(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
