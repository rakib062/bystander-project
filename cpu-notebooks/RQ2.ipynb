{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ2: What makes a bystander? Can it be described by high level concepts? E.g. posing or not\n",
    "- Look at the survey what people think they think\n",
    "- Empirically try to regress / classify bystander from high level concepts\n",
    "- Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: look into hosmer-lemeshow test for goodness of fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "#import helper\n",
    "from definitions import *\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data structure\n",
    "import itertools\n",
    "from collections import Counter,defaultdict\n",
    "\n",
    "#stats amd ml\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm #https://www.statsmodels.org/dev/generated/statsmodels.discrete.discrete_model.LogitResults.html\n",
    "from scipy import stats\n",
    "from sklearn import feature_selection\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.0\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4080, 14), 4080)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_response_cols = ['why_subject', 'why_bystander', 'why_neither']\n",
    "\n",
    "photo_df = pickle.load(open(os.path.join(survey_path, 'photo_df.pkl'), 'rb'))\n",
    "mapping = pickle.load(open(survey_path +'mappings_pilot2','rb'))\n",
    "feature_df = pickle.load(open(os.path.join(survey_path, 'high-feature-df.pkl'), 'rb'))\n",
    "feature_df.shape, len(set(photo_df.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Insert image level concepts in photo_df'''\n",
    "for c in img_level_concepts:\n",
    "    photo_df[c]=feature_df[c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Participants' responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_unique_texts(photo_df, show_res=True):\n",
    "    '''Find unique text responses for subject/bystander in the photo dataframe'''\n",
    "    unique_text_responses = dict()\n",
    "\n",
    "    for t in text_response_cols:\n",
    "        texts = photo_df[[t]]\n",
    "        texts = texts[~texts.isnull().any(axis=1)]\n",
    "        texts = texts.apply(lambda r: r[t].split(','), axis=1)\n",
    "        unique_text_responses[t] = Counter(list(itertools.chain(*texts)))#set(list(itertools.chain(*texts))).difference(set(['Other (please describe)']))\n",
    "\n",
    "        texts = photo_df[[t+'_text']]\n",
    "        texts = texts[~texts.isnull().any(axis=1)]\n",
    "        texts = texts.apply(lambda r: r[t+'_text'].split(','), axis=1)\n",
    "        #unique_text_responses[t]+= Counter(list(itertools.chain(*texts)))\n",
    "\n",
    "    if show_res:\n",
    "        for key in unique_text_responses:\n",
    "            print(key)\n",
    "            for t in unique_text_responses[key].most_common(100):\n",
    "                print('{} ({})'.format(t[0],t[1]))\n",
    "            print()\n",
    "    return unique_text_responses\n",
    "from numpy import std, mean, sqrt\n",
    "\n",
    "#correct if the population S.D. is expected to be equal for the two groups.\n",
    "def cohen_d(x,y):\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    dof = nx + ny - 2\n",
    "    return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1) ** 2 + (ny-1)*np.std(y, ddof=1) ** 2) / dof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For all responses'''\n",
    "_ = show_unique_texts(photo_df=photo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_responses = ['This photo is focused on this person.',\n",
    "     'This person is taking a large space in the photo.',\n",
    "     'This photo is about what this person was doing.',\n",
    "     'This is the only person in the photo.',\n",
    "     'This person was doing the same activity as other subject(s) in this photo.',\n",
    "     'This person was interacting with other subject(s) in this photo.',\n",
    "     'The appearance of this person is similar to other subject(s) of this photo.']\n",
    "\n",
    "bystander_responses = ['This photo is not focused on this person.',\n",
    "    'This person just happened to be there when the photo was taken.',\n",
    "    'Object(s) other than people are the subject(s) of this photo.',\n",
    "    'The activity of this person is similar to other bystander(s) in this photo.',\n",
    "    'Appearance of this person is similar to other bystanders in this photo.',\n",
    "    'There is no specific subject in this photo.',\n",
    "    'This person is interacting with other bystander(s).',\n",
    "    'This person is blocked by other people/object.',\n",
    "    'The activity of this person is different than other subjects(s) in this photo.',\n",
    "    'Appearance of this person is different that other subjects in this photo.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_response_matrix(photo_df, unique_responses, question):\n",
    "    '''\n",
    "    Build a matrix showing which responses occur together.\n",
    "    Note: need to balance for number of times a photo was shown.\n",
    "    '''\n",
    "    matrix = defaultdict(lambda: defaultdict(int))\n",
    "    for response in unique_responses:\n",
    "        other_responses = show_unique_texts(photo_df=\n",
    "            photo_df[photo_df.apply(lambda row: \n",
    "            isinstance(row[question],str) and \\\n",
    "            response in row[question], axis=1)], show_res = False)\n",
    "\n",
    "        row = dict()\n",
    "        for t in other_responses[question].most_common(100):\n",
    "            if t[0]!=response:\n",
    "                row[t[0]] = t[1]\n",
    "        matrix[response] = row\n",
    "    return matrix\n",
    "\n",
    "def get_response_dataframe(photo_df, unique_responses, question):\n",
    "    '''\n",
    "    Build a dataframe where each column is for one unique text response with binary\n",
    "    value indicating if that text is in each of the responses in photo_df.\n",
    "    \n",
    "    Note: need to balance for number of times a photo was shown.\n",
    "    '''\n",
    "    #matrix = defaultdict(lambda: defaultdict(int))\n",
    "    out = dict()\n",
    "    \n",
    "    texts = photo_df[[question]]\n",
    "    texts = texts[~texts.isnull().any(axis=1)]\n",
    "    texts = texts.apply(lambda r: r[question].split(','), axis=1)\n",
    "    \n",
    "    for response in unique_responses:\n",
    "        out[response] = texts.apply(lambda textlist: int(response in textlist))\n",
    "            \n",
    "    \n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "def get_response_dataframe_with_high_columns(photo_df, unique_responses, features, question):\n",
    "    '''\n",
    "    Build a dataframe where each column is for one unique text response with binary\n",
    "    value indicating if that text is in each of the responses in photo_df.\n",
    "    \n",
    "    Note: need to balance for number of times a photo was shown.\n",
    "    '''\n",
    "    out = dict()\n",
    "    \n",
    "    texts = photo_df[[question,'subject_bystander_num']+features]\n",
    "    texts = texts[~texts.isnull().any(axis=1)]\n",
    "    \n",
    "    for response in unique_responses:\n",
    "        out[response] = texts.apply(lambda r: int(response in r[question].split(',')), axis=1)\n",
    "        for c in features:\n",
    "            out[c] = texts[c]\n",
    "    \n",
    "    return pd.DataFrame(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df_subject =get_response_dataframe(photo_df, sub_responses, question='why_subject')\n",
    "response_df_bystander =get_response_dataframe(photo_df, bystander_responses, question='why_bystander')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper.plot_corr_matrix(mat=response_df_subject.corr(method='kendall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper.plot_corr_matrix(mat=response_df_bystander.corr(method='kendall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# responses = get_response_matrix(photo_df, sub_responses, 'why_subject')\n",
    "# df = pd.DataFrame(responses).loc[sub_responses][sub_responses]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper.plot_corr_matrix(mat=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# responses = get_response_matrix(photo_df, bystander_responses, 'why_bystander')\n",
    "# df = pd.DataFrame(responses).loc[bystander_responses][bystander_responses]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper.plot_corr_matrix(mat=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between high level concepts and selected text responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_response_df_subject =get_response_dataframe_with_high_columns(\n",
    "            photo_df, sub_responses, question='why_subject', features = high_level_concepts_num+img_level_concepts\n",
    "                )\n",
    "all_response_df_bystander =get_response_dataframe_with_high_columns(\n",
    "            photo_df, bystander_responses, question='why_bystander', features = high_level_concepts_num+img_level_concepts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The appearance of this person is similar to other subject(s) of this photo.</th>\n",
       "      <th>This is the only person in the photo.</th>\n",
       "      <th>This person is taking a large space in the photo.</th>\n",
       "      <th>This person was doing the same activity as other subject(s) in this photo.</th>\n",
       "      <th>This person was interacting with other subject(s) in this photo.</th>\n",
       "      <th>This photo is about what this person was doing.</th>\n",
       "      <th>This photo is focused on this person.</th>\n",
       "      <th>comfort_num</th>\n",
       "      <th>num_people</th>\n",
       "      <th>person_distance_axes_norm</th>\n",
       "      <th>person_size</th>\n",
       "      <th>photo_place_num</th>\n",
       "      <th>photographer_intention_num</th>\n",
       "      <th>posing_num</th>\n",
       "      <th>replacable_num</th>\n",
       "      <th>was_aware_num</th>\n",
       "      <th>will_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photo_no</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200314</td>\n",
       "      <td>0.247632</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.367190</td>\n",
       "      <td>0.261564</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226073</td>\n",
       "      <td>0.042239</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.047418</td>\n",
       "      <td>0.037202</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.323908</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          The appearance of this person is similar to other subject(s) of this photo.  \\\n",
       "photo_no                                                                                \n",
       "180                                                       0                             \n",
       "169                                                       0                             \n",
       "178                                                       0                             \n",
       "179                                                       0                             \n",
       "170                                                       0                             \n",
       "\n",
       "          This is the only person in the photo.  \\\n",
       "photo_no                                          \n",
       "180                                           0   \n",
       "169                                           0   \n",
       "178                                           1   \n",
       "179                                           0   \n",
       "170                                           0   \n",
       "\n",
       "          This person is taking a large space in the photo.  \\\n",
       "photo_no                                                      \n",
       "180                                                       0   \n",
       "169                                                       0   \n",
       "178                                                       0   \n",
       "179                                                       0   \n",
       "170                                                       0   \n",
       "\n",
       "          This person was doing the same activity as other subject(s) in this photo.  \\\n",
       "photo_no                                                                               \n",
       "180                                                       0                            \n",
       "169                                                       0                            \n",
       "178                                                       0                            \n",
       "179                                                       0                            \n",
       "170                                                       0                            \n",
       "\n",
       "          This person was interacting with other subject(s) in this photo.  \\\n",
       "photo_no                                                                     \n",
       "180                                                       0                  \n",
       "169                                                       1                  \n",
       "178                                                       0                  \n",
       "179                                                       0                  \n",
       "170                                                       0                  \n",
       "\n",
       "          This photo is about what this person was doing.  \\\n",
       "photo_no                                                    \n",
       "180                                                     0   \n",
       "169                                                     0   \n",
       "178                                                     0   \n",
       "179                                                     0   \n",
       "170                                                     0   \n",
       "\n",
       "          This photo is focused on this person.  comfort_num  num_people  \\\n",
       "photo_no                                                                   \n",
       "180                                           1         -2.0           1   \n",
       "169                                           0         -2.0           5   \n",
       "178                                           0         -1.0           1   \n",
       "179                                           1          2.0           3   \n",
       "170                                           1          1.0           1   \n",
       "\n",
       "          person_distance_axes_norm  person_size  photo_place_num  \\\n",
       "photo_no                                                            \n",
       "180                        0.200314     0.247632             -2.0   \n",
       "169                        0.367190     0.261564             -1.0   \n",
       "178                        0.226073     0.042239             -1.0   \n",
       "179                        0.047418     0.037202             -2.0   \n",
       "170                        0.323908     0.016181             -1.0   \n",
       "\n",
       "          photographer_intention_num  posing_num  replacable_num  \\\n",
       "photo_no                                                           \n",
       "180                             -1.0         0.0            -2.0   \n",
       "169                              0.0        -2.0            -2.0   \n",
       "178                             -2.0        -2.0            -1.0   \n",
       "179                              1.0         1.0             0.0   \n",
       "170                              2.0         1.0             0.0   \n",
       "\n",
       "          was_aware_num  will_num  \n",
       "photo_no                           \n",
       "180                -2.0      -1.0  \n",
       "169                -1.0      -1.0  \n",
       "178                -2.0      -1.0  \n",
       "179                 2.0       2.0  \n",
       "170                 2.0       0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_response_df_subject.head()#shape,all_response_df_bystander.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.loc[['180','169','178','179','170']][['subject_bystander_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "sub_dfs=dict()\n",
    "for r in sub_responses:\n",
    "    rows = []\n",
    "    for c in high_level_concepts_num + img_level_concepts:\n",
    "        \n",
    "        cor = stats.spearmanr(all_response_df_subject[c],all_response_df_subject[r])\n",
    "        x = all_response_df_subject[all_response_df_subject[r]==1][c]\n",
    "        y = all_response_df_subject[all_response_df_subject[r]==0][c]\n",
    "        stat, p = stats.ttest_ind(x,y,equal_var=False)\n",
    "        effect_size = cohen_d(x,y)\n",
    "        \n",
    "        if math.fabs(cor[0])>=.1 and cor[1]<.001 and math.fabs(effect_size)>=.2 and p<.001:\n",
    "            dic = {'Feature':c,'correlation coefficient (r)':cor[0], #'p1':cor[1], \n",
    "                   'effect-size (d)': effect_size#, 't-statistic':stat, 'p2':p\n",
    "                  }\n",
    "            rows.append(dic)\n",
    "    if rows:\n",
    "        sub_dfs[r]=pd.DataFrame(rows)#.set_index('col')\n",
    "keys=list(sub_dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This photo is focused on this person.\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  correlation coefficient (r) &  effect-size (d) \\\\\n",
      "Feature          &                              &                  \\\\\n",
      "\\midrule\n",
      "Awareness        &                         0.17 &             0.36 \\\\\n",
      "Pose             &                         0.19 &             0.42 \\\\\n",
      "Comfort          &                         0.15 &             0.30 \\\\\n",
      "Willingness      &                         0.15 &             0.30 \\\\\n",
      "Replaceable      &                        -0.20 &            -0.39 \\\\\n",
      "Size             &                         0.35 &             0.69 \\\\\n",
      "Distance         &                        -0.29 &            -0.63 \\\\\n",
      "Number of people &                        -0.37 &            -0.82 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This person is taking a large space in the photo.\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  correlation coefficient (r) &  effect-size (d) \\\\\n",
      "Feature          &                              &                  \\\\\n",
      "\\midrule\n",
      "Awareness        &                         0.11 &             0.22 \\\\\n",
      "Comfort          &                         0.11 &             0.24 \\\\\n",
      "Willingness      &                         0.12 &             0.25 \\\\\n",
      "Replaceable      &                        -0.20 &            -0.43 \\\\\n",
      "Size             &                         0.38 &             0.83 \\\\\n",
      "Distance         &                        -0.19 &            -0.43 \\\\\n",
      "Number of people &                        -0.20 &            -0.44 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This photo is about what this person was doing.\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  correlation coefficient (r) &  effect-size (d) \\\\\n",
      "Feature   &                              &                  \\\\\n",
      "\\midrule\n",
      "Awareness &                        -0.12 &            -0.24 \\\\\n",
      "Pose      &                        -0.19 &            -0.41 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is the only person in the photo.\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  correlation coefficient (r) &  effect-size (d) \\\\\n",
      "Feature          &                              &                  \\\\\n",
      "\\midrule\n",
      "Awareness        &                         0.11 &             0.21 \\\\\n",
      "Pose             &                         0.10 &             0.21 \\\\\n",
      "Replaceable      &                        -0.12 &            -0.24 \\\\\n",
      "Size             &                         0.27 &             0.65 \\\\\n",
      "Distance         &                        -0.23 &            -0.47 \\\\\n",
      "Number of people &                        -0.61 &            -1.33 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This person was doing the same activity as other subject(s) in this photo.\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  correlation coefficient (r) &  effect-size (d) \\\\\n",
      "Feature          &                              &                  \\\\\n",
      "\\midrule\n",
      "Awareness        &                        -0.11 &            -0.25 \\\\\n",
      "Pose             &                        -0.16 &            -0.36 \\\\\n",
      "Size             &                        -0.29 &            -0.67 \\\\\n",
      "Distance         &                         0.23 &             0.50 \\\\\n",
      "Number of people &                         0.52 &             1.22 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This person was interacting with other subject(s) in this photo.\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  correlation coefficient (r) &  effect-size (d) \\\\\n",
      "Feature          &                              &                  \\\\\n",
      "\\midrule\n",
      "Size             &                        -0.15 &            -0.42 \\\\\n",
      "Distance         &                         0.14 &             0.32 \\\\\n",
      "Number of people &                         0.35 &             0.87 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The appearance of this person is similar to other subject(s) of this photo.\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  correlation coefficient (r) &  effect-size (d) \\\\\n",
      "Feature          &                              &                  \\\\\n",
      "\\midrule\n",
      "Pose             &                        -0.11 &            -0.28 \\\\\n",
      "Size             &                        -0.22 &            -0.57 \\\\\n",
      "Distance         &                         0.18 &             0.44 \\\\\n",
      "Number of people &                         0.41 &             1.05 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in keys:\n",
    "    print(k)\n",
    "    print(sub_dfs[k].set_index('Feature').T.rename(columns=high_level_concepts_name).T.round(2).to_latex())\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "by_dfs=dict()\n",
    "for r in bystander_responses:\n",
    "    rows = []\n",
    "    for c in high_level_concepts_num + img_level_concepts:\n",
    "        \n",
    "        cor = stats.spearmanr(all_response_df_bystander[c],all_response_df_bystander[r])\n",
    "        x = all_response_df_bystander[all_response_df_bystander[r]==1][c]\n",
    "        y = all_response_df_bystander[all_response_df_bystander[r]==0][c]\n",
    "        stat, p = stats.ttest_ind(x,y,equal_var=False)\n",
    "        effect_size = cohen_d(x,y)\n",
    "        \n",
    "        if math.fabs(cor[0])>=.1 and cor[1]<.05 and math.fabs(effect_size)>=.2 and p<.05:\n",
    "            dic = {'Feature':c,'correlation coefficient (r)':cor[0], #'p1':cor[1], \n",
    "                   'effect-size (d)': effect_size#, 't-statistic':stat, 'p2':p\n",
    "                  }\n",
    "            rows.append(dic)\n",
    "    if rows:\n",
    "        by_dfs[r]=pd.DataFrame(rows)#.set_index('col')\n",
    "by_keys=list(by_dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This photo is not focused on this person.\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  correlation coefficient (r) &  effect-size (d) \\\\\n",
      "Feature     &                              &                  \\\\\n",
      "\\midrule\n",
      "Awareness   &                        -0.25 &            -0.59 \\\\\n",
      "Pose        &                        -0.31 &            -0.77 \\\\\n",
      "Comfort     &                        -0.25 &            -0.49 \\\\\n",
      "Willingness &                        -0.26 &            -0.52 \\\\\n",
      "Replaceable &                         0.16 &             0.31 \\\\\n",
      "Photo place &                        -0.22 &            -0.52 \\\\\n",
      "Size        &                        -0.20 &            -0.44 \\\\\n",
      "Distance    &                         0.21 &             0.46 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This person just happened to be there when the photo was taken.\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  correlation coefficient (r) &  effect-size (d) \\\\\n",
      "Feature     &                              &                  \\\\\n",
      "\\midrule\n",
      "Awareness   &                        -0.34 &            -0.70 \\\\\n",
      "Pose        &                        -0.36 &            -0.72 \\\\\n",
      "Comfort     &                        -0.19 &            -0.33 \\\\\n",
      "Willingness &                        -0.22 &            -0.41 \\\\\n",
      "Replaceable &                         0.27 &             0.50 \\\\\n",
      "Photo place &                        -0.24 &            -0.49 \\\\\n",
      "Size        &                        -0.23 &            -0.37 \\\\\n",
      "Distance    &                         0.13 &             0.26 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Object(s) other than people are the subject(s) of this photo.\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  correlation coefficient (r) &  effect-size (d) \\\\\n",
      "Feature          &                              &                  \\\\\n",
      "\\midrule\n",
      "Pose             &                        -0.13 &            -0.24 \\\\\n",
      "Replaceable      &                         0.14 &             0.31 \\\\\n",
      "Number of people &                        -0.12 &            -0.26 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The activity of this person is similar to other bystander(s) in this photo.\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  correlation coefficient (r) &  effect-size (d) \\\\\n",
      "Feature          &                              &                  \\\\\n",
      "\\midrule\n",
      "Replaceable      &                         0.12 &             0.25 \\\\\n",
      "Number of people &                         0.20 &             0.44 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Appearance of this person is similar to other bystanders in this photo.\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  correlation coefficient (r) &  effect-size (d) \\\\\n",
      "Feature          &                              &                  \\\\\n",
      "\\midrule\n",
      "Number of people &                         0.15 &             0.34 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This person is blocked by other people/object.\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  correlation coefficient (r) &  effect-size (d) \\\\\n",
      "Feature     &                              &                  \\\\\n",
      "\\midrule\n",
      "Awareness   &                        -0.15 &            -0.46 \\\\\n",
      "Pose        &                        -0.17 &            -0.54 \\\\\n",
      "Comfort     &                        -0.11 &            -0.29 \\\\\n",
      "Willingness &                        -0.12 &            -0.37 \\\\\n",
      "Replaceable &                         0.14 &             0.38 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Appearance of this person is different that other subjects in this photo.\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  correlation coefficient (r) &  effect-size (d) \\\\\n",
      "Feature     &                              &                  \\\\\n",
      "\\midrule\n",
      "Comfort     &                         0.20 &             0.64 \\\\\n",
      "Willingness &                         0.21 &             0.67 \\\\\n",
      "Photo place &                         0.15 &             0.55 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in by_keys:\n",
    "    print(k)\n",
    "    print(by_dfs[k].set_index('Feature').T.rename(columns=high_level_concepts_name).T.round(2).to_latex())\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How presence of other people influence decision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Number of photos with subjects/bystander across total number of people'''\n",
    "\n",
    "photos = set(photo_df.index.values)\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Load reverse map wheren key=imgeID and values are the list of photono used in the survey.\n",
    "The length of the list indicates how many actual people are in the photo.\n",
    "'''\n",
    "reverse_map = pickle.load(open(os.path.join(survey_path, 'reverse-map.pkl'), 'rb'))\n",
    "\n",
    "'''Load another dict where keys are number of people, and values are list of imgeIds containing that many people'''\n",
    "photo_by_people = pickle.load(open(os.path.join(survey_path, 'photo-by-people.pkl'), 'rb'))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "In a photo with x number of people, how many of them are subject(s)?\n",
    "'''\n",
    "for num_people in range(1, 6):\n",
    "    num_subject = [0]*(num_people+1) # list indicates number of photos with number of people as subject\n",
    "    for photoId in photo_by_people[num_people][:]: #for each photo\n",
    "        #print(photoId,reverse_map[photoId])\n",
    "        indices =[str(id) for id in reverse_map[photoId]] #find indices of this photo in survey dataframe\n",
    "        #print(indices)\n",
    "        df = feature_df.loc[indices] # find out the survey data for the photo indices\n",
    "        sub_count = len(df[df.label==1]) # how many of them are subject\n",
    "        #print(sub_count)\n",
    "        num_subject[sub_count]+=1 # increase count\n",
    "        \n",
    "    #print(num_subject)\n",
    "    print('Total photos with {} people: {}'.format(num_people, len(photo_by_people[num_people])))\n",
    "    for s in range(num_people+1):\n",
    "        print('\\t{} subject: {} ({:.2f}%)'.format(s, num_subject[s], num_subject[s]*100/len(photo_by_people[num_people])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "photo_df.loc[indices][['subject_bystander_num','why_subject']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "When only one person in a 2-person photo are categorized as subjects,\n",
    "what are the reasons for this categorization?\n",
    "'''\n",
    "indices = []\n",
    "for photoId in photo_by_people[2]: #for each photo\n",
    "    idx =[str(id) for id in reverse_map[photoId]] #find indices of this photo in survey dataframe\n",
    "    df = feature_df.loc[idx] # find out the survey data for the photo indices\n",
    "    sub_count = len(df[df.label==1]) # how many of them are subject\n",
    "    if sub_count==1:\n",
    "        indices += idx #find indices of this photo in survey dataframe\n",
    "print(len(indices))\n",
    "_ = show_unique_texts(photo_df=photo_df.loc[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "When both persons in a 2-person photo are categorized as subjects,\n",
    "what are the reasons for this categorization?\n",
    "'''\n",
    "indices = []\n",
    "for photoId in photo_by_people[2]: #for each photo\n",
    "    idx =[str(id) for id in reverse_map[photoId]] #find indices of this photo in survey dataframe\n",
    "    df = feature_df.loc[idx] # find out the survey data for the photo indices\n",
    "    sub_count = len(df[df.label==1]) # how many of them are subject\n",
    "    if sub_count==2:\n",
    "        indices += idx #find indices of this photo in survey dataframe\n",
    "print(len(indices))\n",
    "_ = show_unique_texts(photo_df=photo_df.loc[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Some sample 2-persons photos, where only one of them was categorized as 'subject'.\n",
    "'''\n",
    "helper.draw_photos_from_path(photo_paths=[survey_photo_path+str(i)+'.jpg' for i in [3065,2428,638,3399,3294,3180,3252,3654]], col_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "In some 2-persons photos, while categorizing one of them, the relationships of that person with the other was selected as a reason (e.g. looking/interacting with other subect). But the other person in many of the photos were categorized as bystander. This is probably because the two photos were annotated by different set of subjects. But the relationships among people is likely be important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "When only one person in a 3-person photo are categorized as subjects,\n",
    "what are the reasons for this categorization?\n",
    "'''\n",
    "indices = []\n",
    "for photoId in photo_by_people[3]: #for each photo\n",
    "    idx =[str(id) for id in reverse_map[photoId]] #find indices of this photo in survey dataframe\n",
    "    df = feature_df.loc[idx] # find out the survey data for the photo indices\n",
    "    sub_count = len(df[df.label==1]) # how many of them are subject\n",
    "    if sub_count==1:\n",
    "        indices += idx #find indices of this photo in survey dataframe\n",
    "print(len(indices))\n",
    "_ = show_unique_texts(photo_df=photo_df.loc[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices\n",
    "photo_df.loc[indices[:10]][['why_subject','why_bystander']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify subject/bystander from high level concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Mutual information between a single predictor and the target then select the predictor with \n",
    "the highest MI to train classifier'''\n",
    "\n",
    "for i in range(len(high_level_concepts)):\n",
    "    mi =feature_selection.mutual_info_classif(feature_df[high_level_concepts_num[i]].values.reshape(-1,1),\n",
    "                                              feature_df.label.values,\n",
    "                                              discrete_features='auto', n_neighbors=3, copy=True, random_state=None)\n",
    "    if True or mi[0]>=.2:\n",
    "        print('{}: {:.2f}'.format(high_level_concepts_num[i], mi[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_logit(data, predictors, label='label', normalize=True):\n",
    "    X = data[predictors]\n",
    "    if normalize:\n",
    "        X = X.apply(stats.zscore)\n",
    "    X = sm.add_constant(X)\n",
    "    y = data[label]\n",
    "    return sm.Logit(endog=y, exog=X).fit(disp = False)\n",
    "\n",
    "def print_chisq(model):\n",
    "    print('\\nChisq:{:.2f}, p:{:.2f}\\n'.format(model.llr, model.llr_pvalue))\n",
    "    \n",
    "def get_Rsq(model):\n",
    "    return (model.llr) / (- 2*model.llnull)\n",
    "\n",
    "def get_model_summary(model):\n",
    "    summary = dict()\n",
    "    summary['Chi^2'] = model.llr\n",
    "    summary['p(Chi^2)'] = model.llr_pvalue\n",
    "    summary['R^2'] = (model.llr) / (- 2*model.llnull)\n",
    "    return summary\n",
    "\n",
    "def get_OR(model):\n",
    "    output = model.conf_int()\n",
    "    output['OR'] = model.params\n",
    "    output.columns = ['2.5%', '97.5%', 'OR']\n",
    "    return np.exp(output)[['OR', '2.5%', '97.5%']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_data = feature_df[(feature_df.label==1) | (feature_df.label==-1)]\n",
    "binary_data['label'] = binary_data.apply(lambda row: 1 if row.label==1 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_null_rows(df):\n",
    "    null_columns=df.columns[df.isnull().any()]\n",
    "    return df[df.isnull().any(axis=1)][null_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_data[['photographer_intention_num','label']]\n",
    "feature_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Use all high level concepts'''\n",
    "model = test_logit(binary_data, high_level_concepts_num)\n",
    "print(model.summary())\n",
    "print(pd.DataFrame([get_model_summary(model)]))\n",
    "get_OR(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Use high level concepts found useful from the factor analysis'''\n",
    "model = test_logit(binary_data, ['posing_num','replacable_num'])\n",
    "print(model.summary())\n",
    "print(pd.DataFrame([get_model_summary(model)]))\n",
    "get_OR(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Use high level concepts found useful from the factor analysis combined with predictors\n",
    "with low factor loading'''\n",
    "model = test_logit(binary_data, ['posing_num','replacable_num','photographer_intention_num',\n",
    "                                'photo_place_num'])\n",
    "print(model.summary())\n",
    "print(pd.DataFrame([get_model_summary(model)]))\n",
    "get_OR(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_df[['person_size','person_distance','num_people']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Use high level concepts found useful from the factor analysis combined with the\n",
    "image level predictors'''\n",
    "model = test_logit(binary_data, [ 'posing_num','replacable_num',\n",
    "                                 'person_size','num_people'])\n",
    "print(model.summary())\n",
    "print(pd.DataFrame([get_model_summary(model)]))\n",
    "get_OR(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Use factors (PCA) instead of predictors'''\n",
    "\n",
    "'''NOTE: PCA gives worse result when all the variables are used.'''\n",
    "normalized_data = binary_data[['was_aware_num',\n",
    " 'posing_num',\n",
    " 'comfort_num',\n",
    " 'will_num',\n",
    " 'photographer_intention_num',\n",
    " 'replacable_num'\n",
    " ,'photo_place_num'\n",
    " ]].apply(stats.zscore)\n",
    "n_comp = 2\n",
    "pca = PCA(n_components=n_comp).fit(normalized_data.values)\n",
    "\n",
    "pca_df = pd.DataFrame(pca.components_, columns=high_level_concepts)\n",
    "component_matrix = pca.explained_variance_**.5 * pca_df.T\n",
    "component_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "component_data = pca.transform(normalized_data.values)\n",
    "component_data = pd.DataFrame(component_data, columns=['F1',\"F2\"])\n",
    "\n",
    "X1 = sm.add_constant(component_data)\n",
    "y = binary_data['label'].values\n",
    "model = sm.Logit(endog=y, exog=X1).fit(disp = False)\n",
    "\n",
    "print(model.summary())\n",
    "print(pd.DataFrame([get_model_summary(model)]))\n",
    "get_OR(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Use factors (FA) instead of predictors'''\n",
    "\n",
    "normalized_data = binary_data[['was_aware_num',\n",
    " 'posing_num',\n",
    " 'comfort_num',\n",
    " 'will_num',\n",
    " 'photographer_intention_num',\n",
    " 'replacable_num'\n",
    " ,'photo_place_num'\n",
    " ]].apply(stats.zscore)\n",
    "\n",
    "n_comp = 2\n",
    "\n",
    "fa = FactorAnalysis(random_state=0, svd_method ='lapack', \n",
    "                    n_components=n_comp).fit(normalized_data)\n",
    "\n",
    "factor_data = fa.transform(normalized_data)\n",
    "factor_data = pd.DataFrame(factor_data, columns=['F1',\"F2\"])\n",
    "\n",
    "X2 = sm.add_constant(factor_data)\n",
    "y = binary_data['label'].values\n",
    "model = sm.Logit(endog=y, exog=X2).fit(disp = False)\n",
    "\n",
    "print(model.summary())\n",
    "print(pd.DataFrame([get_model_summary(model)]))\n",
    "get_OR(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''use predictors one by one'''\n",
    "dicts = []\n",
    "for pred in high_level_concepts_num:\n",
    "    model = test_logit(binary_data, [pred])\n",
    "    print(model.summary())\n",
    "    d = get_model_summary(model)\n",
    "    d['Predictor'] = pred\n",
    "    ors = get_OR(model)\n",
    "    d['OR'] = ors.loc[pred].OR\n",
    "    d['2.5%'] = ors.loc[pred]['2.5%']\n",
    "    d['97.5%'] = ors.loc[pred]['97.5%']\n",
    "    dicts.append(d)\n",
    "   # print()\n",
    "pd.DataFrame(dicts)[['Predictor', 'OR', '2.5%', '97.5%','Chi^2', 'p(Chi^2)', 'R^2']].set_index(\"Predictor\").round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = test_logit(binary_data, [ 'posing_num', 'photographer_intention_num'])\n",
    "print(model.summary())\n",
    "print(pd.DataFrame([get_model_summary(model)]))\n",
    "get_OR(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = test_logit(binary_data, [ 'posing_num','replacable_num', 'photographer_intention_num'])\n",
    "print(model.summary())\n",
    "print(pd.DataFrame([get_model_summary(model)]))\n",
    "get_OR(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = test_logit(binary_data, [ 'was_aware_num','replacable_num', 'photographer_intention_num'])\n",
    "print(model.summary())\n",
    "print(pd.DataFrame([get_model_summary(model)]))\n",
    "get_OR(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = test_logit(binary_data, ['photographer_intention_num', 'replacable_num'])\n",
    "print(model.summary())\n",
    "print(pd.DataFrame([get_model_summary(model)]))\n",
    "get_OR(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = test_logit(binary_data, ['photographer_intention_num', 'replacable_num',\n",
    "                                 'was_aware_num'])\n",
    "print(model.summary())\n",
    "print(pd.DataFrame([get_model_summary(model)]))\n",
    "get_OR(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = test_logit(binary_data, ['photographer_intention_num', 'replacable_num',\n",
    "                                 'will_num'])\n",
    "print(model.summary())\n",
    "print(pd.DataFrame([get_model_summary(model)]))\n",
    "get_OR(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_data['dist_sqr'] = binary_data.apply(lambda row: row.person_distance**2, axis=1)\n",
    "binary_data['dist_sqrt'] = binary_data.apply(lambda row: row.person_distance**.5, axis=1)\n",
    "binary_data['size_sqr'] = binary_data.apply(lambda row: row.person_size**2, axis=1)\n",
    "binary_data['size_sqrt'] = binary_data.apply(lambda row: row.person_size**.5, axis=1)\n",
    "binary_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = test_logit(binary_data, [ 'size_sqrt'])\n",
    "print(model.summary())\n",
    "print(pd.DataFrame([get_model_summary(model)]))\n",
    "get_OR(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = test_logit(binary_data, [ 'person_distance', 'size_sqrt'])\n",
    "print(model.summary())\n",
    "print(pd.DataFrame([get_model_summary(model)]))\n",
    "get_OR(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = test_logit(binary_data, [ 'dist_sqr'])\n",
    "print(model.summary())\n",
    "print(pd.DataFrame([get_model_summary(model)]))\n",
    "get_OR(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = test_logit(binary_data, [ 'dist_sqrt'])\n",
    "print(model.summary())\n",
    "print(pd.DataFrame([get_model_summary(model)]))\n",
    "get_OR(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([1307, 615, 318, 206, 137])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
